{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1600)\n",
      "(60, 1600)\n"
     ]
    }
   ],
   "source": [
    "train_negative = np.load('train_negative.npy')\n",
    "train_positive = np.load('train_positive.npy')\n",
    "print train_negative.shape\n",
    "print train_positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.append(train_negative,train_positive)\n",
    "row = int(train_positive.shape[0]+train_negative.shape[0])\n",
    "col = int(train_negative.shape[1])\n",
    "train = train.reshape((row,col))\n",
    "label = np.append(np.zeros((1,train_negative.shape[0])),np.ones((1,train_positive.shape[0])))\n",
    "label = np.array([])\n",
    "for i in xrange(0,train_negative.shape[0]):\n",
    "    label = np.append(label,np.array([0,1]))\n",
    "for i in xrange(0,train_positive.shape[0]):\n",
    "    label = np.append(label,np.array([1,0]))\n",
    "label = label.reshape((row,2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print 'train',np.shape(train),'\\n'\n",
    "print train\n",
    "print 'label',np.shape(label), '\\n'\n",
    "print label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = zip(train,label)\n",
    "random.shuffle(c)\n",
    "train = np.array([e[0] for e in c])\n",
    "label = np.array([e[1] for e in c])\n",
    "train = np.split(train,2); label = np.split(label,2)\n",
    "train_x = train[0] #train_x\n",
    "train_y = label[0] #train_y\n",
    "test_x = train[1] #test_x\n",
    "test_y = label[1] #test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kendo Helmet Recognition: YES:10 ; NO:01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print 'train_x',np.shape(train_x),'\\n',train_x,'\\n'\n",
    "print 'train_y',np.shape(train_y),'\\n',train_y,'\\n'\n",
    "print 'test_x',np.shape(test_x),'\\n',test_x,'\\n'\n",
    "print 'test_y',np.shape(test_y),'\\n',test_y,'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 400\n",
    "#batch_size = 100\n",
    "display_step = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 20 # 1st layer num features\n",
    "n_hidden_2 = 20 # 2nd layer num features\n",
    "n_input = 1600 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 2 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    #Hidden layer with RELU activation\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    #Hidden layer with RELU activation\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) \n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "# Softmax loss\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=y, logits=pred, dim=-1, name=None)) \n",
    "# Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-482-c70fa5604581>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 44890.339843750\n",
      "Epoch: 0009 cost= 14396.368164062\n",
      "Epoch: 0017 cost= 5271.633789062\n",
      "Epoch: 0025 cost= 3091.694580078\n",
      "Epoch: 0033 cost= 1605.508911133\n",
      "Epoch: 0041 cost= 786.340942383\n",
      "Epoch: 0049 cost= 315.943511963\n",
      "Epoch: 0057 cost= 151.771087646\n",
      "Epoch: 0065 cost= 79.293334961\n",
      "Epoch: 0073 cost= 4.626255512\n",
      "Epoch: 0081 cost= 0.000000000\n",
      "Epoch: 0089 cost= 1.390924931\n",
      "Epoch: 0097 cost= 0.000000000\n",
      "Epoch: 0105 cost= 0.000000000\n",
      "Epoch: 0113 cost= 0.000000000\n",
      "Epoch: 0121 cost= 0.000000000\n",
      "Epoch: 0129 cost= 0.000000000\n",
      "Epoch: 0137 cost= 0.000000000\n",
      "Epoch: 0145 cost= 0.000000000\n",
      "Epoch: 0153 cost= 0.000000000\n",
      "Epoch: 0161 cost= 0.000000000\n",
      "Epoch: 0169 cost= 0.000000000\n",
      "Epoch: 0177 cost= 0.000000000\n",
      "Epoch: 0185 cost= 0.000000000\n",
      "Epoch: 0193 cost= 0.000000000\n",
      "Epoch: 0201 cost= 0.000000000\n",
      "Epoch: 0209 cost= 0.000000000\n",
      "Epoch: 0217 cost= 0.000000000\n",
      "Epoch: 0225 cost= 0.000000000\n",
      "Epoch: 0233 cost= 0.000000000\n",
      "Epoch: 0241 cost= 0.000000000\n",
      "Epoch: 0249 cost= 0.000000000\n",
      "Epoch: 0257 cost= 0.000000000\n",
      "Epoch: 0265 cost= 0.000000000\n",
      "Epoch: 0273 cost= 0.000000000\n",
      "Epoch: 0281 cost= 0.000000000\n",
      "Epoch: 0289 cost= 0.000000000\n",
      "Epoch: 0297 cost= 0.000000000\n",
      "Epoch: 0305 cost= 0.000000000\n",
      "Epoch: 0313 cost= 0.000000000\n",
      "Epoch: 0321 cost= 0.000000000\n",
      "Epoch: 0329 cost= 0.000000000\n",
      "Epoch: 0337 cost= 0.000000000\n",
      "Epoch: 0345 cost= 0.000000000\n",
      "Epoch: 0353 cost= 0.000000000\n",
      "Epoch: 0361 cost= 0.000000000\n",
      "Epoch: 0369 cost= 0.000000000\n",
      "Epoch: 0377 cost= 0.000000000\n",
      "Epoch: 0385 cost= 0.000000000\n",
      "Epoch: 0393 cost= 0.000000000\n",
      "Optimization Finished!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.814286\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        #total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        #for i in range(total_batch):\n",
    "            #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: train_x, y: train_y})\n",
    "            # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict={x: train_x, y:train_y})#/total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    t1 = tf.cast(correct_prediction, \"float\").eval({x: test_x, y: test_y})\n",
    "    t2 = tf.cast(correct_prediction, \"float\").eval({x: train_x, y: train_y})\n",
    "    print \"Train Accuracy:\", accuracy.eval({x: train_x, y: train_y})\n",
    "    print \"Test Accuracy:\", accuracy.eval({x: test_x, y: test_y})\n",
    "    np.save('w1',(sess.run(weights['h1'])))\n",
    "    np.save('w2', (sess.run(weights['h2'])))\n",
    "    np.save('wout', (sess.run(weights['out'])))\n",
    "    np.save('b1',(sess.run(biases['b1'])))\n",
    "    np.save('b2',(sess.run(biases['b2'])))\n",
    "    np.save('bout',(sess.run(biases['out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
